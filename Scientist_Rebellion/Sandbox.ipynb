{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0         hashed_userid  masked_username location  following   \n",
      "0           0  53819044136084617463         ****love      NaN          6  \\\n",
      "1           1  63365252551191839332         ****1721      NaN         83   \n",
      "2           2  36591457752220856348        *****hayk   Earth         288   \n",
      "3           3  36387613119620957083    *******nMedia      NaN       3642   \n",
      "4           4  33033899708742110768  ********5338849      NaN        107   \n",
      "\n",
      "   followers  totaltweets usercreateddt              tweetid   \n",
      "0          1          180    2022-04-15  1518491125119877120  \\\n",
      "1         68          713    2021-06-23  1518491215641071619   \n",
      "2      12276        43011    2009-04-10  1518491236147019776   \n",
      "3       2640        15073    2009-02-23  1518491246137856001   \n",
      "4         27          105    2022-04-12  1518491248214040576   \n",
      "\n",
      "               tweetcreatedts  ...   \n",
      "0  2022-04-25 07:24:31.000000  ...  \\\n",
      "1  2022-04-25 07:24:52.000000  ...   \n",
      "2  2022-04-25 07:24:57.000000  ...   \n",
      "3  2022-04-25 07:24:59.000000  ...   \n",
      "4  2022-04-25 07:25:00.000000  ...   \n",
      "\n",
      "                                                text   \n",
      "0  ดัน\\n#LetTheEarthBreath #scientistprotest #end...  \\\n",
      "1  #Hodlers #NFTs #EarthDay #Earn #Binance #BNB #...   \n",
      "2  Hollywood actor Robert Lin @nienchi reads #Ear...   \n",
      "3  Loving all these articles on the Indie Collabo...   \n",
      "4  Philippine #Nature\\n#beauty #EarthDay #monday ...   \n",
      "\n",
      "                                            hashtags language favorite_count   \n",
      "0  [{'text': 'LetTheEarthBreath', 'indices': [4, ...       th              2  \\\n",
      "1  [{'text': 'Hodlers', 'indices': [0, 8]}, {'tex...      und              0   \n",
      "2  [{'text': 'EarthAnthem', 'indices': [42, 54]},...       en              0   \n",
      "3        [{'text': 'EarthDay', 'indices': [53, 62]}]       en              0   \n",
      "4  [{'text': 'Nature', 'indices': [11, 18]}, {'te...       en              2   \n",
      "\n",
      "   is_retweet  original_tweet_id  in_reply_to_status_id  is_quote_status   \n",
      "0       False                  0                      0            False  \\\n",
      "1       False                  0    1517194087165796352            False   \n",
      "2       False                  0                      0            False   \n",
      "3       False                  0                      0            False   \n",
      "4       False                  0                      0            False   \n",
      "\n",
      "   quoted_status_id                 extractedts  \n",
      "0                 0  2022-04-25 14:01:44.317915  \n",
      "1                 0  2022-04-25 14:01:44.303442  \n",
      "2                 0  2022-04-25 14:01:44.287793  \n",
      "3                 0  2022-04-25 14:01:44.273535  \n",
      "4                 0  2022-04-25 14:01:44.258652  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Variable   Type         Data/Info\n",
      "---------------------------------\n",
      "df         DataFrame             Unnamed: 0      <...>308759 rows x 21 columns]\n",
      "pd         module       <module 'pandas' from '/U<...>ages/pandas/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading in csv as panda df\n",
    "df = pd.read_csv(\"0425_to_0703_ScientistRebellionCombinedTweets.csv\")\n",
    "\n",
    "# first rows\n",
    "print(df.head())\n",
    "\n",
    "#double check data type\n",
    "print(type(df))\n",
    "\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'hashed_userid', 'masked_username', 'location', 'following', 'followers', 'totaltweets', 'usercreateddt', 'tweetid', 'tweetcreatedts', 'retweetcount', 'text', 'hashtags', 'language', 'favorite_count', 'is_retweet', 'original_tweet_id', 'in_reply_to_status_id', 'is_quote_status', 'quoted_status_id', 'extractedts']\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6    False\n",
      "7    False\n",
      "8    False\n",
      "9    False\n",
      "Name: is_retweet, dtype: bool\n",
      "0      th\n",
      "1     und\n",
      "2      en\n",
      "3      en\n",
      "4      en\n",
      "5      en\n",
      "6      en\n",
      "7      en\n",
      "8      en\n",
      "9      en\n",
      "10     en\n",
      "11     en\n",
      "12     en\n",
      "13     en\n",
      "14     en\n",
      "15     en\n",
      "16     en\n",
      "17    und\n",
      "18     en\n",
      "19     en\n",
      "20     en\n",
      "21     en\n",
      "22     en\n",
      "23    und\n",
      "24     en\n",
      "25     en\n",
      "26     en\n",
      "27     en\n",
      "28    und\n",
      "29     en\n",
      "30     en\n",
      "31    und\n",
      "32     en\n",
      "33     ja\n",
      "34     en\n",
      "35    und\n",
      "36     en\n",
      "37     en\n",
      "38     en\n",
      "39     en\n",
      "40     en\n",
      "41     en\n",
      "42     en\n",
      "43     en\n",
      "44     en\n",
      "45    und\n",
      "46     en\n",
      "47     en\n",
      "48     en\n",
      "49     en\n",
      "50     en\n",
      "51     en\n",
      "52    und\n",
      "53    und\n",
      "54     en\n",
      "55    und\n",
      "56     en\n",
      "57     es\n",
      "58    und\n",
      "59     en\n",
      "60     en\n",
      "61    und\n",
      "62     en\n",
      "63     en\n",
      "64     en\n",
      "65     en\n",
      "66     en\n",
      "67     en\n",
      "68    und\n",
      "69     en\n",
      "70     en\n",
      "71     en\n",
      "72     en\n",
      "73     en\n",
      "74    und\n",
      "75     en\n",
      "76     en\n",
      "77     en\n",
      "78     en\n",
      "79    und\n",
      "80     en\n",
      "81     en\n",
      "82    und\n",
      "83     en\n",
      "84     en\n",
      "85     en\n",
      "86     en\n",
      "87     en\n",
      "88     en\n",
      "89     en\n",
      "90    und\n",
      "91     ca\n",
      "92     en\n",
      "93     en\n",
      "94     en\n",
      "95    und\n",
      "96     en\n",
      "97     en\n",
      "98     en\n",
      "99     en\n",
      "Name: language, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 400)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(list(df.columns))\n",
    "print(df['is_retweet'].head(10))\n",
    "print(df['language'].head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kamran/opt/anaconda3/envs/ex_spacy_proj/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# loading spacy requirements\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "\n",
    "# ensuring download of spacy's 'small' core english language model\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'hashed_userid', 'masked_username', 'location', 'following', 'followers', 'totaltweets', 'usercreateddt', 'tweetid', 'tweetcreatedts', 'retweetcount', 'text', 'hashtags', 'language', 'favorite_count', 'is_retweet', 'original_tweet_id', 'in_reply_to_status_id', 'is_quote_status', 'quoted_status_id', 'extractedts']\n"
     ]
    }
   ],
   "source": [
    "# print the variable names for df\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filtering for only english tweets and is_retweet == False\n",
    "en_df = df[(df[\"language\"] == \"en\") & (df[\"is_retweet\"] == False)]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.98364885444965\n",
      "41.03215490035814\n",
      "31.99837159490915\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df[\"language\"] == \"en\"])/len(df)*100)\n",
    "print(len(en_df)/len(df[df[\"language\"] == \"en\"])*100)\n",
    "print(len(en_df)/len(df)*100)\n",
    "\n",
    "# 78% of tweets are english\n",
    "# 41% of english tweets are originals\n",
    "# 31% of all tweets are english originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export sample of tweets to manually look over to identify hashtags\n",
    "sample_tweets = en_df.sample(10000)\n",
    "sample_tweets.to_csv(\"sample_tweets.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# heuristic_keywords = ['rebel', 'scientistrebel', 'extinct', 'scientist', 'crisis', 'climate', 'disobedi', 'protest', 'warming', 'extinct']\n",
    "\n",
    "# en_df.loc[:, 'hashtag_any'] = en_df['hashtags'].apply(lambda x: any(keyword.lower() in str(x).lower() for keyword in heuristic_keywords))\n",
    "\n",
    "# for keyword in heuristic_keywords:\n",
    "#     en_df.loc[:, f'hashtag_{keyword}'] = en_df['hashtags'].apply(lambda x: keyword.lower() in str(x).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vw/bpzpvrh5775b97vf11jmnf840000gn/T/ipykernel_1226/1130753148.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_df.loc[:, 'hashtags_list'] = en_df['hashtags'].apply(ast.literal_eval)\n",
      "/var/folders/vw/bpzpvrh5775b97vf11jmnf840000gn/T/ipykernel_1226/1130753148.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  en_df.loc[:, 'confidence_score'] = en_df['hashtags_list'].apply(confidence_score)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy.pipeline.textcat import DEFAULT_SINGLE_TEXTCAT_MODEL\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Co-hashtags function\n",
    "def find_co_hashtags(en_df, target_hashtag):\n",
    "    co_hashtags = Counter()\n",
    "    for index, row in en_df.iterrows():\n",
    "        hashtags_list = eval(row['hashtags'])\n",
    "        hashtag_texts = [hashtag['text'].lower() for hashtag in hashtags_list]\n",
    "        if any(target_hashtag in ht for ht in hashtag_texts):\n",
    "            for hashtag in hashtags_list:\n",
    "                hashtag_text = hashtag['text'].lower()\n",
    "                if target_hashtag not in hashtag_text:\n",
    "                    co_hashtags[hashtag_text] += 1\n",
    "    co_hashtags_df = pd.DataFrame(co_hashtags.most_common(), columns=['co_hashtag', 'count'])\n",
    "    co_hashtags_df.to_csv(f\"{target_hashtag}_cohashtags.csv\", index=False)\n",
    "    return co_hashtags_df\n",
    "\n",
    "rebel_co_hashtags = find_co_hashtags(en_df, 'rebel')\n",
    "extinct_co_hashtags = find_co_hashtags(en_df, 'extinct')\n",
    "\n",
    "# Create weights dictionary\n",
    "def create_weights_dict(df):\n",
    "    total_count = df['count'].sum()\n",
    "    weights = {}\n",
    "    for index, row in df.iterrows():\n",
    "        weights[row['co_hashtag']] = row['count'] / total_count\n",
    "    return weights\n",
    "\n",
    "extinct_weights = create_weights_dict(extinct_co_hashtags)\n",
    "rebel_weights = create_weights_dict(rebel_co_hashtags)\n",
    "\n",
    "# Calculate confidence score\n",
    "def confidence_score(hashtags):\n",
    "    base_score = 0\n",
    "    certain_hashtags = ['scientistrebel', 'extinctionrebel']\n",
    "\n",
    "    for hashtag_dict in hashtags:\n",
    "        tag = hashtag_dict['text'].lower()\n",
    "        if tag in certain_hashtags:\n",
    "            return 1.0\n",
    "        base_score += extinct_weights.get(tag, 0) + rebel_weights.get(tag, 0)\n",
    "\n",
    "    transformed_score = np.log(1 + base_score * 10)\n",
    "    max_score = np.log(1 + 10)\n",
    "    normalized_score = transformed_score / max_score\n",
    "\n",
    "    return min(normalized_score, 1.0)\n",
    "\n",
    "en_df.loc[:, 'hashtags_list'] = en_df.loc[:,'hashtags'].apply(ast.literal_eval)\n",
    "en_df.loc[:, 'confidence_score'] = en_df.loc[:,'hashtags_list'].apply(confidence_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model to categorize text as rebel or not using the confidence score \n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def create_spacy_dataset(df, output_path):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc_bin = DocBin()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        score = row[\"confidence_score\"]\n",
    "        label = \"HIT\" if score >= 0.7 else \"NOT_HIT\"\n",
    "        categories = {\"HIT\": score >= 0.7, \"NOT_HIT\": score < 0.7}\n",
    "\n",
    "        doc = nlp.make_doc(text)\n",
    "        doc.cats = categories\n",
    "        doc_bin.add(doc)\n",
    "\n",
    "    doc_bin.to_disk(output_path)\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "train_df, dev_df = train_test_split(en_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the .spacy files\n",
    "create_spacy_dataset(train_df, \"./train.spacy\")\n",
    "create_spacy_dataset(dev_df, \"./dev.spacy\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex_spacy_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
